{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/glucobench/lib/python3.10/site-packages/statsforecast/core.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# misc tools\n",
    "from typing import List, Union, Dict\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "sys.path.insert(1, '..')\n",
    "os.chdir('..')\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "# analysis tools for time series\n",
    "import statsmodels.api as sm\n",
    "from statsforecast.models import AutoARIMA\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# darts\n",
    "from darts import models\n",
    "from darts import metrics\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "# utils for darts\n",
    "from data_formatter.base import *\n",
    "from utils.darts_dataset import *\n",
    "from utils.darts_processing import *\n",
    "from utils.darts_training import *\n",
    "from utils.darts_evaluation import *\n",
    "# gluformer model\n",
    "from lib.gluformer.model import Gluformer\n",
    "from lib.gluformer.utils.evaluation import test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tblADataRTCGM_Unblinded_RTCGMGroup_6.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_7.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_5.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_4.csv\n",
      "tblADataRTCGM_Blind_ControlGroup.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_1.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_3.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_2.csv\n",
      "tblADataRTCGM_Unblinded_ControlGroup_5.csv\n",
      "tblADataRTCGM_Unblinded_ControlGroup_4.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_12.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_10.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_11.csv\n",
      "tblADataRTCGM_Unblinded_ControlGroup_3.csv\n",
      "tblADataRTCGM_Unblinded_ControlGroup_2.csv\n",
      "tblADataRTCGM_Unblinded_ControlGroup_1.csv\n",
      "tblADataRTCGM_Blind_Baseline.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_9.csv\n",
      "tblADataRTCGM_Unblinded_RTCGMGroup_8.csv\n",
      "         id                 time   gl\n",
      "0       296  2000-09-12 12:43:00   78\n",
      "1       296  2000-09-12 12:48:00   78\n",
      "2       296  2000-09-12 14:53:00  100\n",
      "3       296  2000-09-12 14:58:00  100\n",
      "4       296  2000-09-12 15:03:00  100\n",
      "...     ...                  ...  ...\n",
      "971995   43  2001-03-18 00:23:16  400\n",
      "971996   43  2001-03-18 00:28:16  377\n",
      "971997   43  2001-03-18 00:48:16  383\n",
      "971998   43  2001-03-18 01:03:16  395\n",
      "971999   43  2001-03-18 01:08:15  385\n",
      "\n",
      "[18168110 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is the relative path to the CGM files with original names\n",
    "file_path = os.path.join(\"exploratory_analysis\", \"RT-CGM Randomized Clinical Trial\", \"DataTables\")\n",
    "# Depending on how you have unzipped the file, you may need to edit this slightly\n",
    "\n",
    "# # This will list only the files of CGM data\n",
    "all_files = os.listdir(file_path)\n",
    "\n",
    "# Filter files matching the pattern \"RTCGM\"\n",
    "files = [f for f in all_files if re.search(\"RTCGM\", f)]\n",
    "\n",
    "# One can then loop through the files\n",
    "nfiles = len(files)\n",
    "\n",
    "df_groups = []\n",
    "for i in range(0,len(files)):\n",
    "    filename = files[i] # Get the file name\n",
    "    print(filename)\n",
    "  # Read each csv in\n",
    "    curr = pd.read_csv(os.path.join(file_path, filename))    \n",
    "  \n",
    "  # We don't need this column, so we'll delete it\n",
    "    curr = curr.drop('RecID', axis = 1)\n",
    "    \n",
    "  # Rename columns to standard column names\n",
    "    curr = curr.rename(columns = {\"PtID\":\"id\", \"DeviceDtTm\":\"time\", \"Glucose\": \"gl\"}) \n",
    "  \n",
    "  # Convert time to datetime\n",
    "    curr['time'] = pd.to_datetime(curr['time'], format='ISO8601')\n",
    "\n",
    "  # Format the datetime without microseconds\n",
    "    curr['time'] = curr['time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "  \n",
    "  #Ensure glucose values are recorded as numeric\n",
    "    curr['gl'] = pd.to_numeric(curr['gl'])\n",
    "\n",
    "    df_groups.append(curr)\n",
    "\n",
    "df_all = pd.concat(df_groups)\n",
    "\n",
    "print((df_all))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining covariates\n",
    "\n",
    "# Read in covariate data\n",
    "df_demo = pd.read_csv(os.path.join(file_path, \"tblAPtSummary.csv\")) \n",
    "df_a1c = pd.read_csv(os.path.join(file_path, \"tblALabHbA1c.csv\")) \n",
    "\n",
    "# Convert time to datetime\n",
    "df_a1c['LabHbA1cDt'] = pd.to_datetime(df_a1c['LabHbA1cDt'], format='ISO8601')\n",
    "\n",
    "# Format the datetime without microseconds\n",
    "df_a1c['LabHbA1cDt'] = df_a1c['LabHbA1cDt'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Convert A1c result to numeric\n",
    "df_a1c['LabA1cResult'] = pd.to_numeric(df_a1c['LabA1cResult'])\n",
    "\n",
    "# Drop unnecessary variables\n",
    "df_a1c = df_a1c.drop(['RecID', \"Visit\", \"LabHbA1cNotDone\", \"QCA1cResult\", \"LabHbA1cShipDt\"], axis = 1)\n",
    "\n",
    "# Rename columns\n",
    "df_a1c = df_a1c.rename(columns = {\"PtID\":\"id\", \"LabA1cResult\":\"HbA1c\", \"LabHbA1cDt\":\"HbA1c_time\"}) \n",
    "\n",
    "# Drop unnecessary variables\n",
    "df_demo = df_demo.drop(['RecID', \"HGMReadAvg\", \"RandDt\"], axis = 1)\n",
    "\n",
    "# convert to numeric based on the mapping:\n",
    "# 'M' = 0, \n",
    "# 'F' = 1\n",
    "df_demo['Gender'] = df_demo['Gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# convert to numeric based on the mapping:\n",
    "# 'Unknown/not reported' = 0, \n",
    "# 'More than one race' = 1,\n",
    "# 'White' = 2,\n",
    "# 'Asian' = 3,  \n",
    "# 'Black/African American' = 4, \n",
    "# 'American Indian/Alaskan Native' = 5,\n",
    "# 'Native Hawaiian/Other Pacific Islander' = 6\n",
    "df_demo['Race'] = df_demo['Race'].map({'Unknown/not reported': 0, \n",
    "                                               'More than one race': 1, \n",
    "                                               'White': 2, \n",
    "                                               'Asian': 3, \n",
    "                                               \"Black/African American\": 4, \n",
    "                                               \"American Indian/Alaskan Native\": 5,\n",
    "                                               \"Native Hawaiian/Other Pacific Islander\": 6})\n",
    "\n",
    "# convert to numeric based on the mapping:\n",
    "# 'Unknown/not reported' = 0, \n",
    "# 'Not Hispanic or Latino' = 1,\n",
    "# 'Hispanic or Latino' = 2\n",
    "df_demo['Ethnicity'] = df_demo['Ethnicity'].map({'Unknown/not reported': 0, \n",
    "                                               'Not Hispanic or Latino': 1, \n",
    "                                               'Hispanic or Latino': 3})\n",
    "\n",
    "# convert to numeric based on the mapping:\n",
    "# 'Subject' = 0, \n",
    "# 'Mother' = 1,\n",
    "# 'Father' = 2,\n",
    "# 'Spouse' = 3\n",
    "df_demo['EduCareGvrP'] = df_demo['EduCareGvrP'].map({'Subject': 0, \n",
    "                                               'Mother': 1, \n",
    "                                               'Father': 3, \n",
    "                                               'Spouse': 4})\n",
    "\n",
    "# convert to numeric based on the mapping:\n",
    "# '11' = 0, \n",
    "# '12' = 1,\n",
    "# 'Associates' = 2,\n",
    "# 'Professional' = 3,  \n",
    "# 'Bachelors' = 4, \n",
    "# 'Masters' = 5\n",
    "df_demo['EduCareGvrPEdu'] = df_demo['EduCareGvrPEdu'].map({'11': 0, \n",
    "                                               '12': 1, \n",
    "                                               'Associates': 2, \n",
    "                                               'Professional': 3, \n",
    "                                               \"Bachelors\": 4, \n",
    "                                               \"Masters\": 5})\n",
    "\n",
    "# convert to numeric based on the mapping:\n",
    "# 'Control' = 0, \n",
    "# 'RT-CGM' = 1\n",
    "df_demo['TxGroup'] = df_demo['TxGroup'].map({'Control': 0, 'RT-CGM': 1})\n",
    "\n",
    "# convert to numeric based on the mapping:\n",
    "# 'Pump' = 0, \n",
    "# 'Injections' = 1\n",
    "df_demo['InsulinModality'] = df_demo['InsulinModality'].map({'Pump': 0, 'Injections': 1})\n",
    "\n",
    "# convert to numeric based on the mapping:\n",
    "# '0' = 0, \n",
    "# '1' = 1,\n",
    "# '2' = 2,\n",
    "# '3' = 3,\n",
    "# '>3' = 4\n",
    "df_demo['NumSevHypo'] = df_demo['NumSevHypo'].map({'0': 0, \n",
    "                                               '1': 1, \n",
    "                                               '2': 3, \n",
    "                                               '3': 4,\n",
    "                                               '>3': 5})\n",
    "\n",
    "# Rename columns\n",
    "df_demo = df_demo.rename(columns = {\"PtID\":\"id\"}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge demographic data\n",
    "df_new = df_all.merge(df_demo, on = 'id', how='left')\n",
    "\n",
    "# Issues with left_join() so manually add proper A1c values in full df:\n",
    "\n",
    "# Sort both dataframes by 'id' and relevant time columns for manual merging\n",
    "df_a1c = df_a1c.sort_values(by=['id', 'HbA1c_time']).reset_index(drop=True)\n",
    "df_new = df_new.sort_values(by=['id', 'time']).reset_index(drop=True)\n",
    "\n",
    "# Initialize empty list to store A1c values for df_new\n",
    "HbA1c_values = []\n",
    "\n",
    "# Loop over each row in df_new\n",
    "for i, row in df_new.iterrows():\n",
    "    subject_id = row['id']\n",
    "    cgm_time = row['time']\n",
    "    \n",
    "    # Find most recent A1c value for current subject where HbA1c_time <= cgm_time\n",
    "    relevant_a1c_entries = df_a1c[(df_a1c['id'] == subject_id) & (df_a1c['HbA1c_time'] <= cgm_time)]\n",
    "    \n",
    "    if not relevant_a1c_entries.empty:\n",
    "    # Take most recent A1c value if df_a1c is empty and most recent A1c exists\n",
    "        most_recent_HbA1c = relevant_a1c_entries.iloc[-1]['HbA1c']\n",
    "        \n",
    "    else:\n",
    "    # If no A1c exists before first cgm value, use first available A1c for subject\n",
    "        first_a1c_entry = df_a1c[df_a1c['id'] == subject_id]\n",
    "        \n",
    "        if not first_a1c_entry.empty:\n",
    "        # Use first A1c value\n",
    "            most_recent_HbA1c = first_a1c_entry.iloc[0]['HbA1c']  \n",
    "        else:\n",
    "        # If no A1c data exists at all for this subject, set to NA\n",
    "            most_recent_HbA1c = None  \n",
    "\n",
    "    # Append most recent A1c value to list\n",
    "    HbA1c_values.append(most_recent_HbA1c)\n",
    "\n",
    "\n",
    "# Assign computed A1c values back to df_new\n",
    "df_new['HbA1c'] = HbA1c_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows which have no A1c values or duplicate times per person\n",
    "df_new.dropna(subset=['HbA1c'], inplace=True)\n",
    "df_new = df_new.drop_duplicates(subset=['id', 'time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "df_new.to_csv('./raw_data/tamborlane.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glucobench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
